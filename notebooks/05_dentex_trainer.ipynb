{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10856ab4-1837-475e-a3d4-cc0458fcc570",
   "metadata": {},
   "source": [
    "### Dentex toothmodel image augmentations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5915e27b-9f4c-4cde-b8eb-482878d32cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project module version: 0.0.1.post1.dev16+g367a5b6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import itertools\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import albumentations as alb\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "logger = logging.getLogger(name=__name__)\n",
    "\n",
    "# PyTorch framework\n",
    "import torch\n",
    "\n",
    "# Hugging Face Library\n",
    "from transformers import RTDetrV2ForObjectDetection, RTDetrImageProcessor\n",
    "\n",
    "# Appearance of the Notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(linewidth=110)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import detection as dt\n",
    "from detection.dentexdata import DentexData, fdi_ada_mapping, val_test_split\n",
    "from detection.detrdataset import get_gpu_info, DetectionDatasetFromDF\n",
    "from detection.detrdataset import AugTransform\n",
    "from detection.fileutils import FileOP\n",
    "from detection.imageproc import ImageData, xywh2xyxy, xyxy2xywh, clipxywh\n",
    "\n",
    "print(f'Project module version: {dt.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d37f6ef-6c71-4678-bb16-a33a927584c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs found:  1\n",
      "Current device ID: 0\n",
      "GPU device name:   NVIDIA GeForce GTX 1080 with Max-Q Design\n",
      "PyTorch version:   2.6.0a0+ecf3bae40a.nv25.01\n",
      "CUDA version:      12.8\n",
      "CUDNN version:     90700\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device, device_str = get_gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42be20-942c-47f7-a44f-58f14aaef78d",
   "metadata": {},
   "source": [
    "### Define data locations for this notebook ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc44d60-3bd1-4171-a676-ed67cd1a8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_root = os.path.join(os.environ.get('HOME'), 'data')\n",
    "data_dir = os.path.join(data_root, 'dentex_detection')\n",
    "model_dir = os.path.join(data_dir, 'model')\n",
    "\n",
    "# Image directory (after cropping the data)\n",
    "image_dir = os.path.join(data_dir, 'quadrants')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8bbff1-a537-4171-a94d-766cf4cf7fc9",
   "metadata": {},
   "source": [
    "### Make sure that the data is available ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce2862e-7034-4782-a9e5-9db7ddea8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2531 images.\n"
     ]
    }
   ],
   "source": [
    "# Check the images on disk\n",
    "file_list = glob.glob(os.path.join(image_dir, '*.png'))\n",
    "expected_n_images = 2531\n",
    "if not len(file_list) == expected_n_images:\n",
    "    print(f'WARNING: expected number of images ({expected_n_images}) does not match the number of images on disk.')\n",
    "    print(f'Delete files and start over.')\n",
    "else:\n",
    "    print(f'Found {len(file_list)} images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84e995-6428-41dc-9e34-74c4fb1856ef",
   "metadata": {},
   "source": [
    "### Configure the training functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613387ad-8b41-4a77-81a8-c735cd808050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>pos</th>\n",
       "      <th>bbox</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>fdi</th>\n",
       "      <th>ada</th>\n",
       "      <th>dset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[666, 102, 103, 376]</td>\n",
       "      <td>[[757, 478, 769, 102, 678, 113, 666, 469]]</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[593, 107, 85, 377]</td>\n",
       "      <td>[[666, 484, 678, 110, 607, 107, 604, 299, 619,...</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  quadrant pos                  bbox                                       segmentation  fdi  ada   dset\n",
       "0  train_0_1.png         1   1  [666, 102, 103, 376]         [[757, 478, 769, 102, 678, 113, 666, 469]]   11    8  train\n",
       "1  train_0_1.png         1   2   [593, 107, 85, 377]  [[666, 484, 678, 110, 607, 107, 604, 299, 619,...   12    7  train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation_file_name = 'train_split_250223.parquet'\n",
    "annotation_file = os.path.join(image_dir, annotation_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a90f2c9-d76d-480b-9131-050a8101c4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>pos</th>\n",
       "      <th>bbox</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>fdi</th>\n",
       "      <th>ada</th>\n",
       "      <th>dset</th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[666, 102, 103, 376]</td>\n",
       "      <td>[[757, 478, 769, 102, 678, 113, 666, 469]]</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>train</td>\n",
       "      <td>/app/data/dentex_detection/quadrants/train_0_1...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[593, 107, 85, 377]</td>\n",
       "      <td>[[666, 484, 678, 110, 607, 107, 604, 299, 619,...</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>/app/data/dentex_detection/quadrants/train_0_1...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_0_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[531, 69, 85, 368]</td>\n",
       "      <td>[[587, 437, 616, 357, 607, 72, 534, 69, 531, 4...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>train</td>\n",
       "      <td>/app/data/dentex_detection/quadrants/train_0_1...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_0_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[457, 31, 115, 403]</td>\n",
       "      <td>[[522, 434, 572, 378, 543, 31, 463, 40, 457, 3...</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>/app/data/dentex_detection/quadrants/train_0_1...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_0_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[369, 10, 100, 406]</td>\n",
       "      <td>[[437, 416, 469, 378, 466, 10, 381, 31, 378, 2...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>/app/data/dentex_detection/quadrants/train_0_1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  quadrant pos                  bbox                                       segmentation  fdi  ada   dset                                               file  label\n",
       "0  train_0_1.png         1   1  [666, 102, 103, 376]         [[757, 478, 769, 102, 678, 113, 666, 469]]   11    8  train  /app/data/dentex_detection/quadrants/train_0_1...      7\n",
       "1  train_0_1.png         1   2   [593, 107, 85, 377]  [[666, 484, 678, 110, 607, 107, 604, 299, 619,...   12    7  train  /app/data/dentex_detection/quadrants/train_0_1...      6\n",
       "2  train_0_1.png         1   3    [531, 69, 85, 368]  [[587, 437, 616, 357, 607, 72, 534, 69, 531, 4...   13    6  train  /app/data/dentex_detection/quadrants/train_0_1...      5\n",
       "3  train_0_1.png         1   4   [457, 31, 115, 403]  [[522, 434, 572, 378, 543, 31, 463, 40, 457, 3...   14    5  train  /app/data/dentex_detection/quadrants/train_0_1...      4\n",
       "4  train_0_1.png         1   5   [369, 10, 100, 406]  [[437, 416, 469, 378, 466, 10, 381, 31, 378, 2...   15    4  train  /app/data/dentex_detection/quadrants/train_0_1...      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet(annotation_file)\n",
    "# Create the label column\n",
    "label_name_list = sorted(list(df['ada'].unique()))\n",
    "id2label = dict(zip(range(len(label_name_list)), label_name_list))\n",
    "label2id = {name: label for label, name in id2label.items()}\n",
    "\n",
    "df = df.assign(file=df['file_name'].apply(lambda f: os.path.join(image_dir, f)),\n",
    "               label=df['ada'].apply(lambda i: label2id.get(i)))\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8e29c-ce64-4692-adf0-a21744416318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
